{
  "hash": "ef1baaa1f630aea03788701d282b2943",
  "result": {
    "markdown": "---\ntitle: \"Challenge 10 \"\nauthor: \"Zhongyue Lin\"\ndescription: \"purrr\"\ndate: \"6/20/2023\"\nformat:\n  html:\n    df-print: paged\n    toc: true\n    code-copy: true\n    code-tools: true\ncategories:\n  - challenge_10\n---\n\n\n\n\n## Challenge Overview\n\nThe [purrr](https://purrr.tidyverse.org/) package is a powerful tool for functional programming. It allows the user to apply a single function across multiple objects. It can replace for loops with a more readable (and often faster) simple function call. \n\nFor example, we can draw `n` random samples from 10 different distributions using a vector of 10 means.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 100 # sample size\nm <- seq(1,10) # means \nsamps <- map(m,rnorm,n=n) \n```\n:::\n\n\nWe can then use `map_dbl` to verify that this worked correctly by computing the mean for each sample.  \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamps %>%\n  map_dbl(mean)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  0.9578925  2.0817348  2.8952053  3.9744937  5.0065448  5.9074478\n [7]  7.0210097  8.2019650  9.0584832 10.0644598\n```\n:::\n:::\n\n\n`purrr` is tricky to learn (but beyond useful once you get a handle on it). Therefore, it's imperative that you complete the `purr` and `map` readings before attempting this challenge.  \n\n## The challenge  \n\nUse `purrr` with a function to perform *some* data science task. What this task is is up to you. It could involve computing summary statistics, reading in multiple datasets, running a random process multiple times, or anything else you might need to do in your work as a data analyst. You might consider using `purrr` with a function you wrote for challenge 9.  \n\n\nIn challenge 10, I used the same dataset of **\"hotel_bookings.csv\"** as in challenge 9 as the original dataset\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclean_data <- function(file_path, drop_columns = NULL) {\n  # Read the CSV file\n  data <- read_csv(file_path)\n  \n  # Drop rows with NA values in the 'children' column\n  data$children[is.na(data$children)] <- 0\n  \n  # Combine year, month, and day of month into a single date column and then remove the original columns related to date\n  data <- data %>%\n    mutate(arrival_date = as.Date(paste(arrival_date_year, arrival_date_month, arrival_date_day_of_month, sep = \"-\"), format = \"%Y-%B-%d\")) %>%\n    select(-arrival_date_year, -arrival_date_month, -arrival_date_week_number, -arrival_date_day_of_month)\n\n  # Convert the variables 'is_canceled' and 'is_repeated_guest' to logical (boolean) values\n  data <- data %>%\n    mutate(is_canceled = as.logical(is_canceled), is_repeated_guest = as.logical(is_repeated_guest))\n\n  # Convert categorical variables into factors\n  cat_cols <- c('hotel', 'meal', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', \n                'assigned_room_type', 'deposit_type', 'customer_type', 'reservation_status')\n  data[cat_cols] <- lapply(data[cat_cols], factor)\n\n  # Drop specified columns if provided\n  if (!is.null(drop_columns)) {\n    data <- data %>% select(-all_of(drop_columns))\n  }\n  \n  return(data)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load the data\nhotel_bookings <- clean_data(\"_data/hotel_bookings.csv\")\n```\n:::\n\nIn Challenge 10, we are asked to use functions from the purrr package, which is designed for functional programming and allows us to apply a function to multiple objects for simpler and more readable code. Therefore, we needed to build new functions compatible with the use of purrr.\n\nIn Challenge 9, we created specific task functions, clean_data, calculate_z_score, and plot_histogram, for data cleaning, Z-score calculation, and histogram plotting respectively. However, Challenge 10 is about using purrr for general data science tasks like calculating summary statistics or reading multiple datasets.\n\nTherefore, I created new functions, average_values_by_country and plot_bar, that are more generic, can handle different datasets and columns, and are suited for use with purrr. Specifically, average_values_by_country can compute averages for any given column in any dataset, and plot_bar can plot a bar chart for any two columns in a dataset. These functions can be used with purrr's map function to apply them to multiple columns, allowing for batch processing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Function to compute average values by country\naverage_values_by_country <- function(data, country_col = \"country\", value_col, n_top = 10) {\n  avg_values <- data %>%\n    group_by(!!sym(country_col)) %>%\n    summarise(avg_value = mean(!!sym(value_col), na.rm = TRUE), .groups = \"drop\") %>%\n    top_n(n_top, avg_value)  # Select the top n countries by average value\n  \n  return(avg_values)\n}\n\n# Function to plot a bar chart\nplot_bar <- function(data, x_col, y_col, title = \"\", xlab = \"\", ylab = \"\") {\n  plot <- ggplot(data, aes_string(y_col, x_col)) +  # Switch the x and y columns for a horizontal bar chart\n    geom_bar(stat = \"identity\", fill = \"#69b3a2\", color = \"#e9ecef\", alpha = 0.9) +\n    theme_minimal() +\n    labs(title = title, x = xlab, y = ylab) +\n    coord_flip()  # Flip the coordinates so the bars are horizontal\n  \n  return(plot)\n}\n\n# Columns for which to compute average values and plot bar charts\ncols_to_analyze <- c(\"total_of_special_requests\", \"stays_in_week_nights\")  # modify as needed\n\n# Compute average values and plot bar charts\naverage_values_and_plots <- map(cols_to_analyze, ~{\n  avg_values <- average_values_by_country(hotel_bookings, \"country\", ., n_top = 10)  # Only select the top 10 countries\n  plot <- plot_bar(avg_values, \"country\", \"avg_value\", \n                   title = paste(\"Average\", ., \"by country\"),\n                   xlab = \"Country\",\n                   ylab = paste(\"Average\", .))\n  list(avg_values = avg_values, plot = plot)\n})\n\n# Print the results\naverage_values_and_plots[[1]]$avg_values\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"country\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"avg_value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"ABW\",\"2\":\"1.500000\"},{\"1\":\"BHR\",\"2\":\"1.600000\"},{\"1\":\"BWA\",\"2\":\"3.000000\"},{\"1\":\"CYM\",\"2\":\"2.000000\"},{\"1\":\"NCL\",\"2\":\"2.000000\"},{\"1\":\"PLW\",\"2\":\"2.000000\"},{\"1\":\"SLV\",\"2\":\"1.500000\"},{\"1\":\"STP\",\"2\":\"1.500000\"},{\"1\":\"TMP\",\"2\":\"2.333333\"},{\"1\":\"ZMB\",\"2\":\"2.000000\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\naverage_values_and_plots[[1]]$plot\n```\n\n::: {.cell-output-display}\n![](Zhongyue_Lin_challenge10_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\naverage_values_and_plots[[2]]$avg_values\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"country\"],\"name\":[1],\"type\":[\"fct\"],\"align\":[\"left\"]},{\"label\":[\"avg_value\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"AGO\",\"2\":\"5.831492\"},{\"1\":\"BHS\",\"2\":\"5.000000\"},{\"1\":\"CPV\",\"2\":\"4.416667\"},{\"1\":\"FRO\",\"2\":\"8.400000\"},{\"1\":\"GNB\",\"2\":\"4.888889\"},{\"1\":\"PLW\",\"2\":\"5.000000\"},{\"1\":\"RWA\",\"2\":\"4.500000\"},{\"1\":\"SEN\",\"2\":\"6.090909\"},{\"1\":\"SLE\",\"2\":\"5.000000\"},{\"1\":\"TGO\",\"2\":\"5.500000\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n\n```{.r .cell-code}\naverage_values_and_plots[[2]]$plot\n```\n\n::: {.cell-output-display}\n![](Zhongyue_Lin_challenge10_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\nIn this piece of code, I've defined two functions: `average_values_by_country` and `plot_bar`.\n\nThe `average_values_by_country` function is used to calculate the average values for each country, taking as arguments the data set, the name of the country column, the name of the value column, and a parameter indicating the number of top countries to be selected. This function first groups by the country, then computes the average of the value column, and selects the top `n_top` countries with the highest average values.\n\nThe `plot_bar` function is used to generate a bar chart for a given dataset, taking as arguments the dataset, column names for the x-axis and y-axis, as well as the title and labels for the axes. Within the function, the `geom_bar` function from ggplot2 is used to generate the bar chart, and the coordinates are flipped at the end to get a horizontal bar chart.\n\nAfter these two functions are defined, I've selected two columns to analyze: \"total_of_special_requests\" and \"stays_in_week_nights\" (modifiable as needed), and used the `map` function from `purrr` to apply the previously defined functions to these columns. In the iterative process of the `map` function, I calculate the average values and draw a bar chart for each column, and finally store the results in a list. Each element in the list is a list containing \"avg_values\" (data frame of average values) and \"plot\" (ggplot2 object).\n\nFinally, I print the results, including the data frames of average values and the corresponding bar charts for each analyzed column.\n\nThis way, I can get an intuitive understanding of the average performance of each country on these metrics.\n\n\n\n",
    "supporting": [
      "Zhongyue_Lin_challenge10_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}