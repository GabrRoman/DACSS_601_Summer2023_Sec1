---
title: "Challenge 3 Submission"
author: "Xinpeng Liu"
description: "Tidy Data: Pivoting"
date: "5/30/2023"
format:
  html:
    toc: true
    code-fold: true
    code-copy: true
    code-tools: true
categories:
  - challenge_3
  - animal_weights
  - eggs
  - australian_marriage
  - usa_households
  - sce_labor
---

```{r}
#| label: setup
#| warning: false
#| message: false

library(tidyverse)

knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE)
```

## Challenge Overview

Today's challenge is to:

1.  read in a data set, and describe the data set using both words and any supporting information (e.g., tables, etc)
2.  identify what needs to be done to tidy the current data
3.  anticipate the shape of pivoted data
4.  pivot the data into tidy format using `pivot_longer`

## Read in data

Read in one (or more) of the following datasets, using the correct R package and command.

-   animal_weights.csv â­
-   eggs_tidy.csv â­â­ or organiceggpoultry.xls â­â­â­
-   australian_marriage\*.xls â­â­â­
-   USA Households\*.xlsx â­â­â­â­
-   sce_labor_chart_data_public.xlsx ğŸŒŸğŸŒŸğŸŒŸğŸŒŸğŸŒŸ

```{r}
data<- read_csv("_data/animal_weight.csv")

```

### Briefly describe the data

Describe the data, and be sure to comment on why you are planning to pivot it to make it "tidy"

we choose -   animal_weights.csv â­
```{r}
glimpse(data)

```

we would have three columns: 'IPCC Area', 'Animal Type', and 'Average Weight'. Each row would then represent the average weight of a particular type of animal in a specific region. For example, one row might be 'Eastern Europe', 'Cattle - dairy', '550'.

Pivoting the data in this way makes it "tidy" as per Hadley Wickham's principles:

Each variable forms a column.
Each observation forms a row.
Each type of observational unit forms a table.


## Anticipate the End Result
```{r}
#existing rows/cases
nrow(data)

#existing columns/cases
ncol(data)

#expected rows/cases
nrow(data) * (ncol(data)-1)

# expected columns 
2 + 1
```

## Pivot the Data

Now we will pivot the data, and compare our pivoted data dimensions to the dimensions calculated above as a "sanity" check.
From the data provided, we can see that there are 9 IPCC areas (or rows) and 17 columns. One of these columns is used to identify a case, that is, 'IPCC Area'. So, we have 17 columns that are actual variables (each representing a different animal type).

In this case, after pivoting, we should have n*(k-1) rows in the pivoted dataframe.

Here n is the number of rows (9 IPCC Areas) and k is the number of columns (17). So, the dimensions of the pivoted dataframe should be $9*(17-1)$, which equals 144 rows.

In the pivoted dataframe, we would have three columns: 'IPCC Area', 'Animal Type', and 'Average Weight'. So the total number of data points in the dataframe should remain the same: $9 * 17 (original dataframe) = 144 * 3 (pivoted dataframe)$.

### Challenge: Pivot the Chosen Data

Document your work here. What will a new "case" be once you have pivoted the data? How does it meet requirements for tidy data?
```{r}
# Pivoting the data to a tidy format
animal_weight_pivoted <- pivot_longer(data, 
                                      cols = 'Cattle - dairy':'Llamas', 
                                      names_to = "Animal Type",
                                      values_to = "Average Weight")
print(animal_weight_pivoted, n = nrow(animal_weight_pivoted))

```
The data is now in a tidy format. This fulfills the three principles of tidy data:

1. Each variable forms a column.
2. Each observation forms a row.
3. Each type of observational unit forms a table.

Thus, in this context, a new "case" corresponds to an observation of the average weight for a specific type of animal in a specific area. For instance, the first row tells us that the average weight of dairy cattle in the Indian Subcontinent is 275 units (presumably kilograms or pounds, although the data doesn't specify).

This tidy format makes it easier to perform subsequent data analyses. For instance, we can now easily calculate the overall average weight for each animal type, compare average weights across different areas, or examine the distribution of weights for each animal type, among other analyses.

